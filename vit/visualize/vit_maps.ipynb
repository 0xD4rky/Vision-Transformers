{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.7' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import ViTModel, ViTFeatureExtractor\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\").to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(pixel_values=inputs, output_attentions=True)\n",
    "attentions = outputs.attentions  # A tuple/list of attention layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = \"https://example.com/your_image.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.7' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def visualize_attention_on_image(image, attention_map):\n",
    "    # attention_map: [14x14] for example\n",
    "    attention_map = cv2.resize(attention_map, (image.width, image.height))\n",
    "    attention_map = (attention_map - attention_map.min()) / (attention_map.max() - attention_map.min())\n",
    "    \n",
    "    img_np = np.array(image)\n",
    "    heatmap = cv2.applyColorMap((attention_map*255).astype(np.uint8), cv2.COLORMAP_JET)\n",
    "    blended = cv2.addWeighted(img_np, 0.6, heatmap, 0.4, 0)\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(blended)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "layer_to_visualize = 5\n",
    "head_to_visualize = 0\n",
    "cls_attn = attentions[layer_to_visualize][0, head_to_visualize, 0, 1:].reshape(14,14).cpu().numpy()\n",
    "visualize_attention_on_image(image, cls_attn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def extract_all_heads_attn(attentions, layer):\n",
    "    num_heads = attentions[layer].shape[1]\n",
    "    head_attns = []\n",
    "    for h in range(num_heads):\n",
    "        attn_map = attentions[layer][0, h, 0, 1:].cpu().numpy().reshape(-1)\n",
    "        head_attns.append(attn_map)\n",
    "    return np.stack(head_attns) # shape: [num_heads, #patches]\n",
    "\n",
    "head_attns = extract_all_heads_attn(attentions, layer_to_visualize)\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit_predict(head_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_top_patches(image, attention_map, top_k=5):\n",
    "    flat_attn = attention_map.flatten()\n",
    "    top_indices = np.argsort(flat_attn)[-top_k:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
