# Zero-to-Hero: ViTðŸš€

I have tried to cover all the bases for understanding and implementing Vision Transformers (ViT) and their evolution into Video Vision Transformers (ViViT).
The main focus is on dealing with the spatio-temporal relations using visual transformers.

## 1. Vision Transformer (ViT) Fundamentals

### Surveys and Overviews:

* [Transformers in Vision: A Survey](https://arxiv.org/abs/2101.01169)
* [A Survey of Visual Transformers](https://arxiv.org/abs/2111.06091)

### Key Papers:

* An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale: [Paper](https://arxiv.org/abs/2010.11929) | [Code](https://github.com/google-research/vision_transformer)
* Training data-efficient image transformers & distillation through attention (DeiT): [Paper](https://arxiv.org/abs/2012.12877) | [Code](https://github.com/facebookresearch/deit)


### Concepts and Tutorials:

* "Attention Is All You Need": [Paper](https://arxiv.org/abs/1706.03762)
* "The Illustrated Transformers": [Blog Post](http://jalammar.github.io/illustrated-transformer/)
* "Vision Transformer Explained" [Blog Post](https://theaisummer.com/vision-transformer/)

## 2. Convolutional ViT and Hybrid Models:

* CvT: Introducing Convolutions to Vision Transformers: [Paper](https://arxiv.org/abs/2103.15808) | [Code](https://github.com/microsoft/CvT)
* CoAtNet: Marrying Convolution and Attention for All Data Sizes: [Paper](https://arxiv.org/abs/2106.04803)
* ConViT: Improving Vision Transformers with Soft Convolutional Inductive Biases: [Paper](https://arxiv.org/abs/2103.10697) | [Code](https://github.com/facebookresearch/convit)


## 3. Efficient Transformers and Swin Transformer:

* Swin Transformer: Hierarchical Vision Transformer using Shifted Windows: [Paper](https://arxiv.org/abs/2103.14030) | [Code](https://github.com/microsoft/Swin-Transformer)
* Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions: [Paper](https://arxiv.org/abs/2102.12122) | [Code](https://github.com/whai362/PVT)
* Efficient Transformers: A Survey: [Paper](https://arxiv.org/abs/2009.06732)


## 4. Space-Time Attention and Video Transformers:

* TimeSformer: Is Space-Time Attention All You Need for Video Understanding? [Paper](https://arxiv.org/abs/2102.05095) | [Code](https://github.com/facebookresearch/TimeSformer)
* Space-Time Mixing Attention for Video Transformer: [Paper](https://arxiv.org/abs/2106.05968)
* MViT: Multiscale Vision Transformers: [Paper](https://arxiv.org/abs/2104.11227) | [Code](https://github.com/facebookresearch/SlowFast)


  

